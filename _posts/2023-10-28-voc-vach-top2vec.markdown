---
layout: post
title:  "V·ªçc v·∫°ch s∆° top2vec, v√† b√†i to√°n t√¨m topic !"
date:   2017-11-25 11:52:21 +0700
categories: jekyll update
---
H√¥m nay m√¨nh s·∫Ω chia s·∫ª h·∫≥n 1 th∆∞ vi·ªán m√† m√¨nh m·ªõi ngh√≠a qua g·∫ßn ƒë√¢y v·ªÅ **topic modeling**¬†v√† s**emantic search.** ƒê√≥ l√† **top2vec** (https://github.com/ddangelov/Top2Vec)  

Ch·∫Øc h·∫≥n trong ch√∫ng ta ƒë√£ t·ª´ng nghe t·ªõi b√†i to√°n cluster v·ªÅ vi·ªác t√¨m **topic modeling** t·ª´ m·ªôt ƒë·ªëng c√°c document. Yes, v√† h·∫≥n gensim l√† 1 th∆∞ vi·ªán c·ª±c k√¨ n·ªïi ti·∫øng

Gensim ƒë·∫øn v·ªõi 2 thu·∫≠t to√°n :

Latent Dirichlet Allocation and Probabilistic Latent Semantic Analysis

D√πng c·∫•u tr√∫c doc2vec ƒë·ªÉ contruct

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/d1328f7f-310a-4398-bb82-3e1698f21657/7fcfd0c0-3d1c-483b-afe8-77c5e79b132d/Untitled.png)

Tuy nhi√™n n√≥ c√≥ h·∫°n ch·∫ø l√† ph·∫£i gi·∫£ ƒë·ªãnh tr∆∞·ªõc s·ªë topic, v√† ph·∫£i d·ª±a v√†o [bag-of-words representation] s·∫Ω l√†m m·∫•t ƒëi th·ª© t·ª± v√† ng·ªØ nghƒ©a c·ªßa c√¢u.

Top2Vec l√† thu·∫≠t to√°n cho¬†**topic modeling**¬†v√† s**emantic search (**search ng·ªØ nghƒ©a**)**. N√≥ t·ª± ƒë·ªông x√°c ƒë·ªãnh topic d·ª±a tr√™n text, v√† sinh ra c√°c kh√≠a c·∫°nh nh∆∞ embedded topic, document v√† word vectors. Ph·∫£i k·ªÉ ƒë·∫øn 1 s·ªë t√≠nh nƒÉng ch√≠nh.

![Screen Shot 2023-10-28 at 14.49.02.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/d1328f7f-310a-4398-bb82-3e1698f21657/b756d6d9-848d-4e86-a47f-2f4b431b481c/Screen_Shot_2023-10-28_at_14.49.02.png)

- Ph√°t hi·ªán ra s·ªë l∆∞·ª£ng topic ph√π h·ª£p. l·∫•y ƒë∆∞·ª£c topics v√† size of topic, c√°c topic th·ª´a k·∫ø nhau nh∆∞ th·∫ø n√†o, t√¨m topic b·ªüi keyword, hay t√¨m document b·ªüi topic ho·∫∑c keyword
- T√¨m t·ª´ ƒë·ªìng nghƒ©a
- T√¨m t√†i li·ªáu t∆∞∆°ng t·ª±

Pager:

https://arxiv.org/abs/2008.09470

Th·ª±c ra m√¨nh c≈©ng ch∆∞a hi·ªÉu ho√†n to√†n c√°ch n√≥ c·∫£i thi·ªán l·∫Øm, m√¨nh c√≥ ƒë·ªçc s∆° t√†i li·ªáu, c∆° b·∫£n t√≥m g·ªçn cho c√°c b·∫°n v√†i √Ω üòÑ

N√≥ s·ª≠ d·ª•ng HDBSCAN ƒë·ªÉ t√¨m ra dense areas (v√πng c√≥ ƒë·ªô ƒë·∫≠m ƒë·∫∑c cao ), 

 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/d1328f7f-310a-4398-bb82-3e1698f21657/18d8c9a6-7186-43f0-9c71-b4a6d12d3cbd/Untitled.png)

```
DBSCAN(DB, distFunc, eps, minPts) {
    C¬†:= 0/* Cluster counter */for each point Pin database DB {
if label(P) ‚â† undefinedthencontinue/* Previously processed in inner loop */
        Neighbors N¬†:= RangeQuery(DB, distFunc, P, eps)/* Find neighbors */if |N| < minPtsthen {/* Density check */
            label(P)¬†:= Noise/* Label as Noise */continue
        }
        C¬†:= C + 1/* next cluster label */
        label(P)¬†:= C/* Label initial point */
        SeedSet S¬†:= N \ {P}/* Neighbors to expand */for each point Qin S {/* Process every seed point Q */if label(Q) = Noisethen label(Q)¬†:= C/* Change Noise to border point */if label(Q) ‚â† undefinedthencontinue/* Previously processed (e.g., border point) */
            label(Q)¬†:= C/* Label neighbor */
            Neighbors N¬†:= RangeQuery(DB, distFunc, Q, eps)/* Find neighbors */if |N| ‚â• minPtsthen {/* Density check (if Q is a core point) */
                S¬†:= S ‚à™ N/* Add new neighbors to seed set */
            }
        }
    }
}
```

Gi·∫£i th√≠ch thu·∫≠t to√°n:

1. **Input Parameters:**
    - **`DB`**: The database of data points you want to cluster.
    - **`distFunc`**: The distance function used to measure the similarity or dissimilarity between data points.
    - **`eps`**: The maximum radius (distance) within which a data point is considered a neighbor of another point.
    - **`minPts`**: The minimum number of data points required within the **`eps`** radius for a point to be considered a core point.
2. **Initialization:**
    - **`C`**: A variable used to keep track of the cluster counter.
    - The algorithm starts by initializing all data point labels as "undefined."
3. **Main Loop:**
    - For each point **`P`** in the database **`DB`**, it checks whether the point has already been processed (labeled). If it has, it continues to the next point.
4. **Range Query:**
    - It performs a range query to find the neighbors of the current point **`P`** within a radius of **`eps`** using the given distance function **`distFunc`**.
5. **Density Check:**
    - If the number of neighbors found in the range query is less than **`minPts`**, the point **`P`** is labeled as "Noise" (an outlier) and the algorithm continues to the next point.
6. **Cluster Assignment:**
    - If there are at least **`minPts`** neighbors, it increments the cluster counter **`C`** and assigns the label **`C`** to the current point **`P`**. This point becomes the initial point of a new cluster.
7. **Seed Set:**
    - A seed set **`S`** is initialized with the neighbors found in the range query, excluding the current point **`P`**.
8. **Expanding the Cluster:**
    - For each point **`Q`** in the seed set **`S`**, the algorithm checks whether **`Q`** was previously labeled as "Noise." If so, it changes its label to the cluster label **`C`**.
    - If **`Q`** was already labeled with a cluster or is undefined, it continues to the next point in the seed set.
    - If **`Q`** is neither noise nor previously processed, it assigns the cluster label **`C`** to it.
    - A new range query is performed on **`Q`** to find its neighbors.
    - If the number of neighbors found in this query is greater than or equal to **`minPts`**, those neighbors are added to the seed set **`S`**.
9. The algorithm continues this process until all points in the database **`DB`** have been assigned to a cluster or labeled as noise.


![Screen Shot 2023-10-28 at 15.53.12.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/d1328f7f-310a-4398-bb82-3e1698f21657/beb3c259-f504-4294-a872-26af7ca14dde/Screen_Shot_2023-10-28_at_15.53.12.png)

D√πng UMAP ƒë·ªÉ gi·∫£m dimension tr∆∞·ªõc khi caculate

C√°c b·∫°n c√≥ tham kh·∫£o nhi·ªÅu h∆°n ·ªü ƒë√¢y 

https://www.analyticsvidhya.com/blog/2020/09/how-dbscan-clustering-works/

## Sample code tranning d√πng top2vec

L·∫•y data tin t·ª©c, th·∫≠t ra c√°c b·∫°n c≈©ng c√≥ th·ªÉ search tr√™n m·∫°ng r·∫•t nhi·ªÅu ngu·ªìn tin t·ª©c b√°o ti·∫øng vi·ªát üòÑ, ·ªü ƒë√¢y m√¨nh ch·ªâ code v√≠ d·ª•.

```bash
from regress_adapter import get_news_date

data = get_news_date('2022-01-01')
print(data.head())
```

```bash
title  \
0  G√≥c nh√¨n chuy√™n gia: Kh·∫£ nƒÉng th·ªã tr∆∞·ªùng c√≤n ƒë...   
1  V√¨ sao v·ª£ ch·ªìng t·ªïng gi√°m ƒë·ªëc CII mu·ªën b√°n s·∫°c...   
2  Ch·ª©ng kho√°n gi·∫£m 4 tu·∫ßn li√™n t·ª•c, nh√† ƒë·∫ßu t∆∞ l...   
3  Kh·∫£i Ho√†n Land (KHG) mu·ªën ch√†o b√°n ri√™ng l·∫ª 18...   
4  ƒê·∫•t Xanh Services (DXS) ch·ªët ng√†y ph√°t h√†nh 12...   

                                             content                date  
0  \n\n\n\n\nTIN M·ªöI\n\n\n\n\n    Th·ªã tr∆∞·ªùng ch·ª©n... 2023-08-10 12:58:00  
1  \n\n\n\n\r\n                    CII: \n\n\n\n\... 2023-09-10 09:35:00  
2  \n\n\n\n\nTIN M·ªöI\n\n\n\n\n\nKh√¥ng ph·ª•c h·ªìi nh... 2023-07-10 19:01:00  
3  \n\n\n\n\r\n                    KHG: \n\n\n\n\... 2023-06-10 10:20:00  
4  \n\n\n\n\r\n                    DXS: \n\n\n\n\... 2023-05-10 01:00:00
```

```bash
t = data['title'] + data['content']
data_list = t.to_list()
```

C√°c function x·ª≠ l√≠ b√≥c t√°ch t·ª´ v√† lo·∫°i b·ªè c√°c d·∫•u c√¢u lung tung üòÉ

(D√πng underthesea ƒë·ªÉ t√°ch cho chu·∫©n nhe)

```python
import re
import helper
import numpy as np
from importlib import reload
from underthesea import word_tokenize

reload(helper)

def segmentation(text):
    try:
        return word_tokenize(text, format="text")
    except (TypeError, AttributeError):
        return ''

def split_words(post, return_type='sentence'):
    texts = segmentation(post)
    try:
        t = [str(x.strip('0123456789%@$.,=+-!;/()*"&^:#|\n\t\' ').lower()) for x in texts.split()]
        filtered_list = [item for item in t if item != ""]
        if return_type == 'token':
            return filtered_list
        elif return_type == 'sentence':
            return ' '.join(filtered_list)

    except TypeError:
        return []
    
def split_tokens(post):
    return split_words(post, return_type='token')
```

X√≥a b·ªõt c√°c ƒëo·∫°n vƒÉn b·ªã r·ªóng (1 thao t√°c l√†m s·∫°ch d·ªØ li·ªáu ) üòÑ

```python
X_2 = [words for words in map(split_words, data_list) if len(words) > 0]
```

ƒêo·∫°n code training c·ª±c k√¨ quan tr·ªçng 

```python
model = Top2Vec(X_2, embedding_model="distiluse-base-multilingual-cased", speed = "learn", tokenizer=split_tokens)
```

Save model l·∫°i ƒë·ªÉ d√πng l·∫°i nh√© 

```python
# write code save model to file
model.save('./cached/top2vec.model')
```

L·∫•y s·ªë topic

```python
num_topic = model.get_num_topics()
print(num_topic)
```

```python
47
```

L·∫•y topic size v√† topic index

```python
topic_sizes, topic_nums = model.get_topic_sizes()
print(topic_sizes, topic_nums)
```

```python
[999 600 422 397 346 344 307 305 293 290 265 258 254 228 227 210 194 182
 166 159 147 144 136 130 119 115 105 100  91  89  89  80  79  73  70  66
  62  57  50  47  47  44  42  38  34  32  23] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46]
```

Search topic d·ª±a tr√™n keyword nh√© m·ªçi ng∆∞·ªùi 

```python
topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=["ch·ª©ng_kho√°n"], num_topics=5)
for topic in topic_nums:
    model.generate_topic_wordcloud(topic)
```